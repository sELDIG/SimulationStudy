---
title: "Analysis"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# Read and process data

```{r}
library(RColorBrewer)
library(dplyr)
library(tidyr)
library(ranger)
library(stringr)

# Read in simulated tree data
simuData <- read.csv("./experiments/uniform_sampling_experiment/process_parameter_values_and_tree_metrics_sign_corrected.csv", stringsAsFactors = T)
simuDataKey <- read.csv("./experiments/uniform_sampling_experiment/simulation_parameters_key.csv")


head(simuDataKey)

statisticsIndices1 = 25:43 # all 19 tree metrics
statisticsIndices2 = c(26, 28, 29, 33:43) # # Only the tree metrics not strongly correlated with richness, --excluding log10S, PD, Colless, Sackin, Yule.PDA.ratio
statisticsIndices3 = 25:50 # all 19 tree metrics plus first 7 PCA
  
statisticsIndices = statisticsIndices3

statistics = colnames(simuData)[statisticsIndices]

nStats = length(statisticsIndices)

# Indices for the 5 simulation processes (env, dis, mut, nic, com)
predictorsIndices = c(14,16,18,20,22)
predictors = colnames(simuData)[c(14,16,18,20,22)]
numModelsPerPredictor = c(5, 7, 4, 7, 6)

# 8 models
models = levels(simuData$model)
```

# Consistency analysis

## Agggregate statistics

```{r}
signMat = matrix(nrow = length(statistics), 
                 ncol = length(predictors),
                 dimnames = list(statistics, predictors))
R2Mat = disAg = disAg2 = signMat

R2MatFull = signMatFull = array(dim = c(length(statistics), length(predictors), length(models)),
                               dimnames = list(statistics, predictors, models)) 


for(i in 1:length(statisticsIndices)){
  for(j in 1:length(predictorsIndices)){
    R2 = sig = rep(NA, length(models))
    for(k in 1:length(models)){
      tmp = simuData[simuData$model == models[k],]
      x = scale(tmp[,statisticsIndices[i]])
      y = tmp[,predictorsIndices[j]]
      if(! all(is.na(y))){
      
      corRes = cor.test(x,y, method = "spearman")
        
      # fit <- summary(lm(y ~ x))
      # R2[k] = fit$r.squared
      # sig[k] = ifelse(fit$coefficients[2,4] <0.05, sign(fit$coefficients[2,1]), 0)
      R2[k] = corRes$estimate
      sig[k] = corRes$p.value
      } else{
        R2[k] = NA
        sig[k] = NA
      }
    }
    R2MatFull[i,j,] = R2
    signMatFull[i,j,] = sig
    R2Mat[i,j] = mean(R2, na.rm = T)
    signMat[i,j] = sum(sig, na.rm = T) / sum(!is.na(sig))
    disAg[i,j] = abs(sum(sig == 1, na.rm = T) - sum(sig == -1, na.rm = T)) / abs(sum(sig %in% c(1,-1), na.rm = T))
    disAg2[i,j] = max(sum(sig == 1, na.rm = T), sum(sig == -1, na.rm = T)) / abs(sum(sig %in% c(1,-1), na.rm = T))
  }
}
```

## Full plot

```{r}
image.real3d <- function(mat, mat2, xCol = c("darkblue","blue", "lightblue", "gray94", "pink","red", "darkred"), 
                       range = c(-1,1), x.labels = dimnames(mat)[[1]],      y.labels = dimnames(mat)[[2]]) { 
  
  newMat = matrix(nrow = dim(mat)[1], ncol = 50)
  for(i in 1:dim(mat)[1]){
    for(k in 1:dim(mat)[2])
      newMat[i,(1+(k-1)*10):((k-1)*10 + dim(mat)[3])] = mat[i,k,]
  }
  
  newMat <- t(newMat)
  xpos = rep(0:(dim(mat)[2]-1), each = dim(mat)[3])*10 + 1:dim(mat)[3] 
  ypos = 1:dim(mat)[1]
  fields::image.plot(x = 1:50, y = 1:nStats, z = newMat, axes = FALSE, zlim = range, 
                     col = colorRampPalette(xCol)(30), xlab = "", ylab = "")
  
  abline(v = c(0,10,20,30,40,50) + 0.5)
  abline(v = c(0,10,20,30,40,50) - 1.5)
  abline(h = c(1:(nStats +1)) + 0.5)
  axis(2, at = 1:nrow(mat), labels = x.labels, las = 2, cex.axis = 0.8)
  axis(3, at = seq(5, 45, by = 10), labels = y.labels, las = 1)
  axis(1, at = xpos, labels = rep(dimnames(mat)[[3]], 5), cex.axis = 0.65, las = 2)
  
  # text(x = xpos, y = 0, srt = 45, adj = 1, xpd = TRUE, labels = rep(dimnames(mat)[[3]], 5), cex = 0.65)
  box() 
  
  for(i in 1:dim(mat2)[1]){
    for(k in 1:dim(mat2)[2]){
       for(j in 1:dim(mat2)[3])
        if(!is.na(mat2[i,k,j]) & mat2[i,k,j] < 0.05){
          text(x = 10*(k-1) +j,  y = i, labels = "*" )
      }
    }
  }
}

par(mar = c(5,10,5,3))
image.real3d(R2MatFull, signMatFull)

```

## Averaging across models

Define plotting function for 2d

```{r}

image.real <- function(mat, xCol = c("blue", "white", "white", "red"), 
                       range = c(-1,1), x.labels = rownames(mat), y.labels = colnames(mat)) { 
  mat <- t(mat)[,nrow(mat):1]
  fields::image.plot(mat, axes = FALSE, zlim = range, 
                     col = colorRampPalette(xCol)(30))
  axis(1, at = seq(0, 1, length = nrow(mat)), labels = x.labels)
  axis(2, at = seq(0, 1, length = ncol(mat)), labels = y.labels, las = 2)
  box() 
}


# 2-panel figure
par(mfrow = c(1, 2), mar = c(3,11,3,3))

# Values: % agreement, Color: average sign
image.real(signMat, x.labels = c('env', 'dis', 'nic', 'mut', 'com')) 

for(i in 1:length(statisticsIndices)){
  for(j in 1:length(predictorsIndices)){
    text((j-1)/(length(predictorsIndices)-1),
         1-(i-1)/(length(statisticsIndices)-1), 
         labels = 100*round(disAg2[i,j], digits = 2))
  }
}
mtext(paste0(rep("(", 5), numModelsPerPredictor, rep(")", 5)), 1, at = seq(0, 1, length = ncol(signMat)), line = 2)
title(main = "% agreement in effect direction")

# Values: average correlation coefficient, Color: average sign
image.real(signMat, x.labels = c('env', 'dis', 'nic', 'mut', 'com')) 
for(i in 1:length(statisticsIndices)){
  for(j in 1:length(predictorsIndices)){
    text((j-1)/(length(predictorsIndices)-1),
         1-(i-1)/(length(statisticsIndices)-1), 
         labels = round(R2Mat[i,j], digits = 2))
  }
}
mtext(paste0(rep("(", 5), numModelsPerPredictor, rep(")", 5)), 1, at = seq(0, 1, length = ncol(signMat)), line = 2)
title(main = "Average correlation coefficient")


image.real(R2Mat, range = c(-1,1), xCol = c("beige", "firebrick2")) 
title(main = "R2 between parameter and tree metric")

for(i in 1:length(statisticsIndices)){
  for(j in 1:length(predictorsIndices)){
    text((j-1)/(length(predictorsIndices)-1),
         1-(i-1)/(length(statisticsIndices)-1), 
         labels = round(R2Mat[i,j], digits = 2))
  }
}


image.real(disAg2) 
for(i in 1:length(statisticsIndices)){
  for(j in 1:length(predictorsIndices)){
    text((j-1)/(length(predictorsIndices)-1),
         1-(i-1)/(length(statisticsIndices)-1), 
         labels = round(disAg[i,j], digits = 2))
  }
}


```





# Model inversion 

## Old analysis


```{r}
# Random Forests for predicting parameter values from tree metrics
library(ranger)

# Preliminary analysis using all tree metrics

predictability = array(dim = c(length(statistics), length(predictors), length(models)))
predictabilityR2 = array(dim = c(length(predictors), length(models)))

for(j in 1:length(predictorsIndices)){
  for(k in 1:length(models)){
    tmp = simuData[simuData$model == models[k],c(predictorsIndices[j], statisticsIndices)]
    tmp = tmp[complete.cases(tmp),]
    if(nrow(tmp) > 0){
      form = as.formula(paste(predictors[j], "~ ."))
      x = ranger(form, data = tmp, importance = 'permutation',
                 scale.permutation.importance = T)
      predictability[,j,k] = importance(x)     
      predictabilityR2[j,k] = x$r.squared
    } 
  }
}


rownames(predictabilityR2) = predictors
colnames(predictabilityR2) = models

image.real(predictabilityR2, range = c(0,1), xCol = c("beige", "firebrick2"))
title(main = "Random forest predictability [R2]")


predMean = apply(predictability, c(1,2), mean, na.rm = T)
predSD = apply(predictability, c(1,2), sd, na.rm = T)

rownames(predMean) = statistics
colnames(predMean) = predictors

image.real(predMean, range = NULL, xCol = c("beige", "firebrick2"))
title(main = "mean variable importance for predicting across models")

for(i in 1:length(statisticsIndices)){
  for(j in 1:length(predictorsIndices)){
    text((j-1)/(length(predictorsIndices)-1),
         1-(i-1)/(length(statisticsIndices)-1), 
         labels = round(predMean[i,j] / predSD[i,j], digits = 2))
  }
}
```

### Analysis using only the tree metrics that are not strongly correlated with richness

```{r}
statistics2 = colnames(simuData)[statisticsIndices2]



predictability2 = array(dim = c(length(statistics2), length(predictors), length(models)))
predictability2R2 = array(dim = c(length(predictors), length(models)))

for(j in 1:length(predictorsIndices)){
  for(k in 1:length(models)){
    tmp = simuData[simuData$model == models[k],c(predictorsIndices[j], statisticsIndices2)]
    tmp = tmp[complete.cases(tmp),]
    if(nrow(tmp) > 0){
      form = as.formula(paste(predictors[j], "~ ."))
      x = ranger(form, data = tmp, importance = 'permutation',
                 scale.permutation.importance = T)
      predictability2[,j,k] = importance(x)     
      predictability2R2[j,k] = x$r.squared
    } 
  }
}


rownames(predictability2R2) = predictors
colnames(predictability2R2) = models

image.real(predictability2R2, range = c(0,1), xCol = c("beige", "firebrick2"))
title(main = "Random forest [R2] (non-richness metrics)")


predMean2 = apply(predictability2, c(1,2), mean, na.rm = T)
predSD2 = apply(predictability2, c(1,2), sd, na.rm = T)

rownames(predMean2) = statistics2
colnames(predMean2) = predictors

image.real(predMean2, range = NULL, xCol = c("beige", "firebrick2"))
title(main = "mean variable importance (non-richness metrics)")

for(i in 1:length(statisticsIndices2)){
  for(j in 1:length(predictorsIndices)){
    text((j-1)/(length(predictorsIndices)-1),
         1-(i-1)/(length(statisticsIndices2)-1), 
         labels = round(predMean2[i,j] / predSD2[i,j], digits = 2))
  }
}
```


## Between models



```{r}
predictors[2]

modelsTMP = models[-5]

CpredictabilityR2 = array(dim = c(length(modelsTMP), length(modelsTMP)))

for(k in 1:length(modelsTMP)){
  train = simuData[simuData$model == modelsTMP[k],c(predictorsIndices[2], statisticsIndices2)]
  train = train[complete.cases(train),]
  if(nrow(train) > 0){
    form = as.formula(paste(predictors[2], "~ ."))
    x = ranger(form, data = train)
  } 
  for(j in 1:length(modelsTMP)){
    test = simuData[simuData$model == modelsTMP[j],c(predictorsIndices[2], statisticsIndices2)]
    test = test[complete.cases(test),]
    if(nrow(test) > 0 & k != j){
      y = predict(x, test)
      CpredictabilityR2[k,j] = cor.test(y$predictions, test$dis1, method = "kendall")
    }
  }
}

# could add row and column sums 

rownames(CpredictabilityR2) = modelsTMP
colnames(CpredictabilityR2) = modelsTMP

tmp = predictability2R2[2,-5]

for(i in 1:length(modelsTMP)) CpredictabilityR2[i,i] = tmp[i]

xCol = c("darkblue","blue", "lightblue", "gray94", "pink","red", "darkred")

par(mar = c(5,5,5,5))

image.real(CpredictabilityR2, range = c(-1,1), xCol = xCol)
title(main = paste("Random forest cross-model predictability [R2], mean =", mean(predictabilityR2)), xlab = "test", ylab = "train")

for(i in 1:length(modelsTMP)){
  for(j in 1:length(modelsTMP)){
    text((j-1)/(length(modelsTMP)-1),
         1-(i-1)/(length(modelsTMP)-1), 
         labels = round(CpredictabilityR2[i,j], digits = 2))
  }
}
```







# Case studies


## within each model

Run random forests within each simulation model in order to predict model parameter values from simulation-derived tree shape metrics. Then plug in empirical tree shape metrics to infer a process parameter value assuming that the tree arose from the processes represented by a particular simulation model.


```{r}

# run a version of metricsForManyTrees() to get tree metric output for empirical sister clades (but that function assumes diff model ID naming convention, so had to manually tweak)
empiricalMetrics = read.table('empiricalSisterClades_treeOutput.txt', header = T, sep = '\t')
empiricalMetrics$clade = rep(c(1,2), 6)
empiricalMetrics$cladeName = c('Xenarthra', 'Afrotheria',
                               'Carnivora/\nPerissodactyla', 'Cetartiodactyla',
                               'Swifts', 'Hummingbirds',
                               'Rodentia', 'Lagomorpha',
                               'Coraciiformes', 'Passeriformes',
                               'Pelecaniformes', 'Ciconiiformes')
empMetrics = empiricalMetrics[, 4:22]
empMetrics2 = empiricalMetrics[, c(5, 7, 8, 12:23)]

predictedValues2 = data.frame(tree = character(),
                              model = character(), 
                              predictor = character(),
                              value = numeric())

predictability2 = array(dim = c(length(statistics2), length(predictors), length(models)))
predictability2R2 = array(dim = c(length(predictors), length(models)))


for(j in 1:length(predictorsIndices)){
  for(k in 1:length(models)){
    tmp = simuData[simuData$model == models[k],c(predictorsIndices[j], statisticsIndices2)]
    tmp = tmp[complete.cases(tmp),]
    if(nrow(tmp) > 0){
      form = as.formula(paste(predictors[j], "~ ."))
      x = ranger(form, data = tmp, importance = 'permutation',
                 scale.permutation.importance = T)
      predictions = predict(x, data = empMetrics2)
      
      tmpPredictions = data.frame(tree = word(empiricalMetrics$tree, 1, sep = fixed('.')),
                                  model = rep(models[k], nrow(empMetrics2)),
                                  predictor = rep(predictors[j], nrow(empMetrics2)),
                                  value = predictions$predictions)
      
      predictedValues2 = rbind(predictedValues2, tmpPredictions)
      
    } 
  }
}



# Need to standardize the predicted parameter values relative to the range of values examined within a given model.  
#   scaled = (x - min) / (max - min)          

#so first need to identify min and max values for each model-parameter combo:

modelParamRange = simuData %>%
  group_by(model) %>%
  summarize(env1Min = min(env1, na.rm = T),
            env1Max = max(env1, na.rm = T),
            com1Min = min(com1, na.rm = T),
            com1Max = max(com1, na.rm = T),
            dis1Min = min(dis1, na.rm = T),
            dis1Max = max(dis1, na.rm = T),
            nic1Min = min(nic1, na.rm = T),
            nic1Max = max(nic1, na.rm = T),
            mut1Min = min(mut1, na.rm = T),
            mut1Max = max(mut1, na.rm = T))

# Note that for some model/parameter combinations, the modeler varied parameter values uniformly on a log scale, while for others values varied uniformly on an arithmetic scale.

# I examined the skewness values of all sets of values, and determined that each of the following combinations had a skewness of 0.7 or greater and merited being log-transformed prior to scaling. 
# (Otherwise, the scaled values, e.g. in model 'hs' for dis1 or mut1 are close to 0)

# ca: mut1, com1
# hs: dis1, mut1
# xe: dis1, mut1

modelParamRange$com1Min[modelParamRange$model == 'ca'] = log10(modelParamRange$com1Min[modelParamRange$model == 'ca'])
modelParamRange$com1Max[modelParamRange$model == 'ca'] = log10(modelParamRange$com1Max[modelParamRange$model == 'ca'])
modelParamRange$dis1Min[modelParamRange$model %in% c('hs', 'xe')] = log10(modelParamRange$dis1Min[modelParamRange$model %in% c('hs', 'xe')])
modelParamRange$dis1Max[modelParamRange$model %in% c('hs', 'xe')] = log10(modelParamRange$dis1Max[modelParamRange$model %in% c('hs', 'xe')])
modelParamRange$mut1Min[modelParamRange$model %in% c('hs', 'xe', 'ca')] = log10(modelParamRange$mut1Min[modelParamRange$model %in% c('hs', 'xe', 'ca')])
modelParamRange$mut1Max[modelParamRange$model %in% c('hs', 'xe', 'ca')] = log10(modelParamRange$mut1Max[modelParamRange$model %in% c('hs', 'xe', 'ca')])

# Rearrange
modelParamMinMax = data.frame(model = rep(modelParamRange$model, 5), 
                              predictor = rep(c('env1', 'com1', 'dis1', 'nic1', 'mut1'), each = 8),
                              minVal = c(modelParamRange$env1Min, modelParamRange$com1Min, modelParamRange$dis1Min, 
                                         modelParamRange$nic1Min, modelParamRange$mut1Min),
                              maxVal = c(modelParamRange$env1Max, modelParamRange$com1Max, modelParamRange$dis1Max, 
                                         modelParamRange$nic1Max, modelParamRange$mut1Max))


# Also need to log-transform the same parameter values in predictedValues2
predictedValues2$value[predictedValues2$model == 'ca' & predictedValues2$predictor %in% c('mut1', 'com1')] = 
  log10(predictedValues2$value[predictedValues2$model == 'ca' & predictedValues2$predictor %in% c('mut1', 'com1')])

predictedValues2$value[predictedValues2$model %in% c('hs', 'xe') & predictedValues2$predictor %in% c('mut1', 'dis1')] = 
  log10(predictedValues2$value[predictedValues2$model %in% c('hs', 'xe') & predictedValues2$predictor %in% c('mut1', 'dis1')])


# Function for rescaling a value between the min and max such that the scaled value varies between 0 and 1.
# If either the min or max are NA, Inf, or -Inf, returns NA
scaleFunction = function(value, min, max) {
  
  if (!min %in% c(-Inf, NA, Inf) & !max %in% c(-Inf, NA, Inf)) {
    
    scaledValue = (value - min) / (max - min)
  
  } else {
  
    scaledValue = NA
  
  }
  return(scaledValue)
}




scaledPredictions2 = predictedValues2 %>%
  left_join(modelParamMinMax, by = c('model', 'predictor')) %>%
  mutate(pair = str_extract(tree, "[1-9]"),
         clade = rep(c(1, 2), 174))

scaledPredictions2$scaledValue = apply(scaledPredictions2[, c('value', 'minVal', 'maxVal')], 1, 
                             function(x) scaleFunction(value = x[1], min = x[2], max = x[3]))

#Okabe-Ito color blind friendly palette
modelColors = data.frame(model = unique(predictedValues2$model),
                         color = c(rgb(0,0,0),
                                   rgb(230/255, 159/255, 0),
                                   rgb(86/255, 180/255, 233/255),
                                   rgb(0, 158/255, 115/255),
                                   rgb(240/255, 228/255, 66/255),
                                   rgb(0, 114/255, 178/255),
                                   rgb(213/255, 94/255, 0),
                                   rgb(204/255, 121/255, 167/255)))

scaledPredictions2 = left_join(scaledPredictions2, modelColors, by = 'model')



# Plot of model inversion for dispersal across 6 empirical sister clade pairs
# --bottom panel illustrates relative magnitude of mean.Iprime which was identified as the tree metric most diagnostic of dispersal

pairs = unique(scaledPredictions2$pair)

# Specify dispersal process
pro = 'dis1' 

par(mfrow = c(2, 3), mar = c(3, 3, 1, 0), oma = c(0, 3, 0, 0))

for (p in pairs) {
    
  tmp = filter(scaledPredictions2, pair == p, predictor == pro)
    
  plot(c(0.5,2.5), range(tmp$scaledValue), type = 'n', xaxt = 'n', xlab = "", ylab = "", las = 1,
       ylim = c(0, 1), yaxt = 'n')
  axis(1, at = 1:2, labels = empiricalMetrics$cladeName[empiricalMetrics$pair == p], 
       tck = 0, cex.axis = 1.1)
  axis(2, at = seq(0.3, 1, by = 0.1), las = 1)
 
  abline(h = 0.26)
     
  for (m in unique(tmp$model)) {
      
    points(tmp$clade[tmp$model==m], tmp$scaledValue[tmp$model==m], type = 'b', col = tmp$color[tmp$model==m], lwd = 3)
    text(2.1, tmp$scaledValue[tmp$model==m & tmp$clade == 2], m, adj = 0)
  }

  # Add barplots showing empirical values of mean.Iprime for the two sister clades
  par(new = T)
  barplot(empiricalMetrics$mean.Iprime[empiricalMetrics$pair == p], 
          yaxt = 'n', ylim = c(0, 2.5), space = .95, border = NA, xlim = c(0.25, 4.5))  
  
  if (p %in% c(1, 5)) {
    mtext("Tree Metric:", 2, cex = .9, line = 3, at = 0.3)
    mtext("mean I'", 2, cex = 1, line = 0.5, at = 0.3)
    mtext("Inferred Dispersal", 2, cex = 1.1, line = 3, at = 1.6)
  }
  
}


```
